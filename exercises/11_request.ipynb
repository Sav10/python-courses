{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 21_request.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la page à ouvrir\n",
    "url = 'https://api.ipify.org'\n",
    "# On ouvre l'URL et on stock le resultat dans response\n",
    "response = requests.get(url)\n",
    "# Pour lire le texte de la page, on utilise '.text'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statut de la réponse (200 : OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afficher le texte de la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'URL pour trouver le pays correspondant à une ip ou un nom de domaine\n",
    "infourl = 'http://ip-api.com/xml/liberation.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tâches:\n",
    "- changer le site (ou l'ip) cible\n",
    "- afficher le contenu de la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ouvre l'autre URL et on stock le resultat dans response\n",
    "infourl = 'http://ip-api.com/xml/liberation.fr'\n",
    "response = requests.get(infourl)\n",
    "xml = response.text\n",
    "# Ce resultat est au format XML (comme du HTML),\n",
    "# il faut que Python puisse le comprendre\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "# Affiche des valeur\n",
    "print (f\"Pays: {soup.query.country.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tâches:\n",
    "- changer le site (ou l'ip) cible\n",
    "- afficher d'autre information avec xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"URL DES ANNONCES SUR EBAY\"\n",
    "# On ouvre l'autre URL et on stock le resultat dans body\n",
    "body = requests.get(base).text\n",
    "# Parse le HTML avec Beautiful Soup\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "# Liste des titres avec un selecteur CSS\n",
    "titles = soup.select(\"SELECTEUR CSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    # La fonction 'strip()' permet de supprimer les espaces avant et après un texte\n",
    "    print title.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tâches:\n",
    "- obtenir une liste d'annonces de vélos en faisant une recherche sur ebay.fr\n",
    "- les titres des annonces peuvent être trouvés avec le selecteur CSS '.lvresult h3 .vip' ou '.s-item__title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".s-item , .s-item__info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_text(soup, selector):\n",
    "    elements = soup.select(selector)\n",
    "    if len(elements) > 0:\n",
    "        return elements[0].text.strip()\n",
    "\n",
    "def select_href(soup, selector):\n",
    "    elements = soup.select(selector)\n",
    "    if len(elements) > 0:\n",
    "        return elements[0].get('href')\n",
    "\n",
    "\n",
    "base = \"https://www.ebay.fr/sch/i.html?_from=R40&_trksid=m570.l1313&_nkw=v%C3%A9lo&_sacat=0\"\n",
    "# On ouvre l'autre URL et on stock le resultat dans body\n",
    "body = requests.get(base).text\n",
    "# Parse le HTML avec Beautiful Soup\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "# Tous les éléments de la liste\n",
    "list_items = soup.select(\".s-item\")\n",
    "\n",
    "for item in list_items:\n",
    "    # L'élément .lvprice contient le prix, on affiche uniquement les annonce avec un pri\n",
    "    price = select_text(item, '.s-item__price')\n",
    "    # COMPLETEZ ICI le selecteur CSS\n",
    "    title = select_text(item, '')\n",
    "    # COMPLETEZ ICI le selecteur CSS\n",
    "    url = select_href(item, '')\n",
    "\n",
    "    print (f\"{title} à {price} sur {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tâches:\n",
    "- dans chaque résultat, extraire: le titre, le prix et le lien vers l'annonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
